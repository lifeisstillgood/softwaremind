==========================================================================
If AI can replace your job tomorrow, Plain old software can today
==========================================================================


What is AI?
What is intelligence?
What does the philosophical disucssion of intelligence matter - not much

AI as a replacement for maangers and rotework.
Well we alrady know how to replce rotework. Automation has been doing that for
ages.  If it is not done already then there are political or business model
concerns. POlitical means having AI will not easily solve the problem. Business
model usually means bribery or other thigns you dont want to involve AI in.

The other reason AI will struggle is lack of feedback. In major compaies this is
startlingly bad. ball balancing trick. THose feedback mechanisms do not work ...
outside of a programmable company. In fact this is a good *defintion of a
programmable company* - the feedback loop is fast enough to be useful.



Will AI affect the future of work - yes, but not as much as "sky is falling",
and not as much as "robotic replacement" because companies nned to be software
literte - arranged so that one can iterate over them.  They need to programmable
- and if so then you dont need AI.  You just need to write code.  But then you
  get "free interns".

Role of training data, and journalism.  How dow e find ground truth in polarised
world. Well world is always beenpolarised - see, Luther. We find it
in evidence, in OSINT, in reliable journlism - World Service being simplest
example of a massive foot gun for British people. I would put Wikipedia as the
next battle ground - and how do we deal with that?
See also text books, and education syllabuses. 


HunterBrook - future if jountlaism
-----------
yes I think
https://www.axios.com/2023/11/02/hunterbrook-hedge-fund-journalists
because we want to know what is "truth"

somehiw we need to pay for it - the paper based distribution mattered 
its disaggregated now but we still need scoiety level training day

some is science, NIH ans NICE
some is hunterbrook looking at OSINT
or just see hunterbrook as OsINT

aee the globe thing for snowcrash 


Future Expansion
================

Build a python LLM from scratch
https://www.freecodecamp.org/news/how-to-build-a-large-language-model-from-scratch-using-python/

Word2vec, basic word encoding, a Queen is a female King.        


  AI is not magic, it simply tries to solve the robotics issues
  - what is the perception of the real world
  - what is the model of the real world
  - what is the perception of my situaiton in the world
  - what is the next action 

  (OODA)

  But AI is able to *build* a model in a amazing new way,
  but a model of the world is not useful without perception of 
  world and own ability.

  So if AI can build some model of a "perfect manager brain", 
  it will still need to be fed perceptions of the operations daily 
  ANd are those already being fed upwards - honestly turns out mostly no.
  THey are stuck in siloes, they are filter through powerpoint presrntations
  and massaged by project managers, 

  AI can learn to balance a ball on a stick.  But if we have unclear
  information about where the ball is, how the stick is moving etc,
  it will perform at least as badly as an actual human manager.

  The perception feedback must be good for any model to be transferrable.
  If it is bad then how do we behave - the same way most managers behave - 
  find a few trusted lieutenants who can find *just enough* information 
  to be representative and keep churning and find that playing politics in
  feudal environment is almost always more profitable than fixing the
  perceptiin and action problems.

  AI is not magic. if you think some or all of job can be repaced by AI
  then the question is, why cant it be repaced today woth traditional software
  its not volume of data - no human can compete
  its access to tools and ots decision politics
  if AI can replace a manager tomorrow then software can do it today 



AI as an embedded knowledge tool - spanner wmbeds other peoples knowledge - thisnis that to larger extent


Chapter: Journalism is labelling the training data for the world
=================================================================
  * LLMs, AI, journalism
  Training data matters 

AI and journalism 
-------------------

Challenges of training data and bias
We started with 'easy' problems - facial recgnition and black african
descent. Oh look Stanford has white male phd students.
Bias in Generative AI: show me images of nazi stormtroopers.
Hang on. Why are there chinese or black african stomrtroopers?? Huh
Look at how skin cacner detection - is there a ruler in the image? Is the
image taken under flouresent light ?

- there is *almost certainly* child porn in training data. That bothers me
  enormously.
- But what about 

Fixing it. "publish your training data". Thats a *positive* move, but, "hey we
trained on these 5 billion images. What do you do with those? How do you even
classifiy them?

CV scanning. Anecodatally a large corporation decides to use AI to scan CVs,
and identify young people most likely to succeed in the corporation. It is given
the CVs of everyone in the company, and gets to work. It flatout rejects every
CV from a woman. They remove the gender from the CVs - it still does it.
They dig in - why is this going to be rejected. Basically, women reach a certain
point in the company, and rise no higher. Therefore women wont succeed at this
company.  Now what? It is correctly analysing the problem. Its not the answer
you want.

But it is a part of the democractic bet - AI is not fooled by the double-think
bias humans introduce to be able to survive.  Any totaltitarian regieme has that
in it.  But only an egalitarian democracy has the ability to change to make
itself truly equal.

Do we want to do that? THose who will obviously gain say yes. THose who will
lose, and what of those who will lose big? Shall we introduce a wealth tax?


World building matters (ability to plan is basically
ability to predict future. THis is a hall mark of intelligence - also why
people with bad internal models make poor decisions, and why its so hard to
get people with vastly differing models to understand each otehr - used to be
limited to crime. now... politics?  Its why its vital to edicate people to have
same model at first, its also why edication laevels make biggest
differentiator in politics, and also why choosing the first model makes your
'side' more relevant. See north korean education camps. But also see how
many people did nto believe societ model but kept stum'

Any how - world building - effective model - how 

LLM - conceptually similar to knearest neighbour
and word2vec 


Journalism and the training data 
————

timeline is the problem - sympathy for facebook because 
how dontounorgnaise timeline ? cannot show eveything - cannot shownjust friends because broing
so whats the algorithm
? ask a go ernment they dont say just say "dont destroy democeacy"
but perhaps problem is "timeline" - dont do timeline do education or agent with best interet s of the user 

training data matters
---------------------
Google and pagerank soon became google and returned tonhomepage data as feedback onnquality
Tesla owns data on when the car braked or jerked or gas applied and 
can record that and upload it nightly and use for modelling
journlism is societies way of marking training data
textbooks are way of marking trianong data 
science is way to doscover correct weights for feedback

now why is it that google keeps
my clicks or my steering as ots own proprietary data

health data - it shoukd be public data 
by default

licensing or otherwise but not unavailable


